{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Практика 6: Атака по переносу (Transfer Attack) на модели ИИ**\n",
        "\n",
        "Белов Владимир Станиславович ББМО-01-23\n",
        "\n",
        "Изучить концепцию атаки по переносу, где противоречивые примеры, созданные для одной модели, используются для атаки на другую модель. Это задание требует создания нескольких моделей, генерации противоречивых примеров для одной модели и проверки их на другой модели.\n",
        "\n",
        "**Задачи:**\n",
        "\n",
        "1. Загрузить несколько моделей, обученных на датасете MNIST.\n",
        "2. Изучить теоретические основы атаки по переносу.\n",
        "3. Реализовать атаку FGSM на одну модель и проверить, как противоречивые примеры влияют на\n",
        "другую модель.\n",
        "4. Оценить точность обеих моделей на противоречивых примерах и проанализировать\n",
        "переносимость атак.\n"
      ],
      "metadata": {
        "id": "QhU6gJEyESBD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Шаг 1**: Загрузка и создание двух различных моделей."
      ],
      "metadata": {
        "id": "c79qUjBzEkbb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONlzRtLND-Ko",
        "outputId": "3845af50-2c65-487f-fb50-191bf87dea28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8746 - loss: 0.4460\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9657 - loss: 0.1192\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9766 - loss: 0.0783\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9832 - loss: 0.0556\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9877 - loss: 0.0402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.9152 - loss: 0.2957\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 11ms/step - accuracy: 0.9848 - loss: 0.0506\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.9910 - loss: 0.0296\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.9939 - loss: 0.0201\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.9964 - loss: 0.0120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "# Загрузка данных MNIST\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "# Нормализация данных\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "# Преобразование меток в one-hot encoding\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "# Модель 1: Простая полносвязная нейронная сеть\n",
        "model1 = Sequential([\n",
        " Flatten(input_shape=(28, 28)),\n",
        " Dense(128, activation='relu'),\n",
        " Dense(10, activation='softmax') ])\n",
        "\n",
        "# Компиляция модели\n",
        "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=\n",
        "['accuracy'])\n",
        "# Обучение модели\n",
        "model1.fit(train_images, train_labels, epochs=5)\n",
        "# Сохранение модели\n",
        "model1.save('mnist_model1.h5')\n",
        "# Модель 2: Свёрточная нейронная сеть (CNN)\n",
        "model2 = Sequential([\n",
        " Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        " MaxPooling2D((2, 2)),\n",
        " Flatten(),\n",
        " Dense(128, activation='relu'),\n",
        " Dense(10, activation='softmax')\n",
        "])\n",
        "# Компиляция модели\n",
        "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=\n",
        "['accuracy'])\n",
        "# Обучение модели\n",
        "model2.fit(train_images.reshape(-1, 28, 28, 1), train_labels, epochs=5)\n",
        "# Сохранение модели\n",
        "model2.save('mnist_model2.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Шаг 2**: Реализация атаки FGSM на первую модель.\n",
        "\n",
        "Мы применим атаку FGSM (Fast Gradient Sign Method) к первой модели, чтобы создать\n",
        "противоречивые примеры.\n"
      ],
      "metadata": {
        "id": "i7pLmpH_GVnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Функция FGSM атаки\n",
        "def fgsm_attack(image, epsilon, gradient):\n",
        "    # Применение знака градиента к изображению\n",
        "    perturbed_image = image + epsilon * np.sign(gradient)\n",
        "    perturbed_image = np.clip(perturbed_image, 0, 1)  # Ограничение значений в диапазоне [0, 1]\n",
        "    return perturbed_image\n",
        "\n",
        "# Генерация противоречивых примеров\n",
        "def generate_fgsm_adversarial(model, images, labels, epsilon):\n",
        "    adversarial_images = []\n",
        "    for i in range(len(images)):\n",
        "        image = tf.convert_to_tensor(images[i].reshape(1, 28, 28, 1), dtype=tf.float32) # Конвертирует размер под формат модели\n",
        "        label = tf.convert_to_tensor(labels[i].reshape(1, -1), dtype=tf.float32) # Конвертируем one-hot вектор в индекс\n",
        "\n",
        "        # Вычисление градиента\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(image)\n",
        "            prediction = model(image)\n",
        "            loss = tf.keras.losses.categorical_crossentropy(label, prediction)\n",
        "\n",
        "        gradient = tape.gradient(loss, image)\n",
        "        adv_image = fgsm_attack(image.numpy(), epsilon, gradient.numpy())\n",
        "        adversarial_images.append(adv_image.reshape(28, 28))\n",
        "\n",
        "    return np.array(adversarial_images)\n",
        "\n",
        "# Создание противоречивых примеров для первой модели\n",
        "epsilon = 0.1\n",
        "adversarial_images_model1 = generate_fgsm_adversarial(model1, test_images, test_labels, epsilon)\n",
        "\n"
      ],
      "metadata": {
        "id": "QUtflkKwGV2_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Шаг 3**: Оценка противоречивых примеров на обеих моделях.\n",
        "\n",
        "Теперь мы проверим, как эти противоречивые примеры влияют на обе модели — первую, для\n",
        "которой они были созданы, и вторую, которая их не видела.\n"
      ],
      "metadata": {
        "id": "jxdeWw6oOuWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Оценка первой модели на противоречивых примерах\n",
        "test_labels_argmax = np.argmax(test_labels, axis=1) # Преобразование onehot меток в целые числа\n",
        "loss1, acc1 = model1.evaluate(adversarial_images_model1, test_labels)\n",
        "print(f'Accuracy of model1 on adversarial examples: {acc1}')\n",
        "\n",
        "# Оценка второй модели на противоречивых примерах (перенос атаки)\n",
        "adversarial_images_model1_reshaped = adversarial_images_model1.reshape(-1, 28, 28, 1)\n",
        "loss2, acc2 = model2.evaluate(adversarial_images_model1_reshaped, test_labels)\n",
        "print(f'Accuracy of model2 on adversarial examples from model1: {acc2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MB1DQH1DO0BF",
        "outputId": "03946ba7-2fc0-4b2c-d9a2-bbf91cf0ff92"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.0990 - loss: 6.2986\n",
            "Accuracy of model1 on adversarial examples: 0.13079999387264252\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.1432\n",
            "Accuracy of model2 on adversarial examples from model1: 0.9632999897003174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Шаг 4**: Анализ переносимости атак.\n",
        "\n",
        "Проанализируем, насколько успешно атака переносится с одной модели на другую."
      ],
      "metadata": {
        "id": "9aeVQyCwO9mh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Генерация противоречивых примеров для второй модели\n",
        "adversarial_images_model2 = generate_fgsm_adversarial(model2, test_images.reshape(-1, 28, 28, 1), test_labels, epsilon)\n",
        "# Оценка первой модели на противоречивых примерах второй модели\n",
        "loss3, acc3 = model1.evaluate(adversarial_images_model2.reshape(-1, 28, 28), test_labels)\n",
        "print(f'Accuracy of model1 on adversarial examples from model2: {acc3}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2H_7N62O92J",
        "outputId": "ba4a894e-8322-49e0-bae5-f1dc1e89db9f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.9198 - loss: 0.2577\n",
            "Accuracy of model1 on adversarial examples from model2: 0.9329000115394592\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод:**\n",
        "\n",
        "Точность модели на противоречивых примерах имеет низкую точность в размере ~13.10%, как обычная имеет 96.30%. Переность атаки 1 модели на 2 показал небольшое снижение точности ~ 3.04%, что говорит об устойчивости модели к атаке, которая создана для другой модели."
      ],
      "metadata": {
        "id": "0PoHylLGRZHQ"
      }
    }
  ]
}